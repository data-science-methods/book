# Some Data-Cleaning Tools #

```{r, echo = FALSE, message = FALSE}
library(printr)
```
```{r child = 'knitr_config.Rmd'}
```

- reading: @WickhamTidyData2014

## Rectangular and non-rectangular data ##

(ref:oseroff-spicer) Tweet by Nathan Oseroff-Spicer (\\@nathanoseroff): 'It makes sense, though, since there are rows and columns. It's scientific'. Source: <https://twitter.com/nathanoseroff/status/1321565407568867332>

```{r, echo = FALSE, fig.cap = "(ref:oseroff-spicer)"}
knitr::include_graphics(file.path('images', 'data', 'Oseroff-Spicer.png'))
```

- Data represented in rows and columns is called *rectangular data*. 
- Common non-rectangular forms include XML and JSON
    - Sometimes you might get data in the form of a PDF or image.  This is called *cursÃ¨d data*. 

## Tidy Data ##

- conventions for organizing data for analysis
    1. Each variable forms a column.
    2. Each observation forms a row.
    3. Each type of observational unit forms a table.
        

- Example: student demographics and major, for students who took a philosophy course at UC Davis, 2005-2015

```{r, echo = FALSE, fig.show = 'hold', out.width = c('60%', '110%'), fig.cap = "Two tables in a tidy dataset. The first table records students' majors during each term they were enrolled; the second (next figure) records demographics.  The tables have different units of observation, but can be linked using the ID (internal to this dataset) for an analysis at the level of individual students. Other tables in this dataset include final grades for philosophy courses taken by the students, and demographics of the instructors of those courses."}
knitr::include_graphics(file.path('images', 'data', 'tidy-1.png'))
knitr::include_graphics(file.path('images', 'data', 'tidy-2.png'))
```

- slightly rephrased
    - 1 table = 1 unit of observation
        - student-term (major)
        - student (demographics)
    - 1 row = 1 unique observed unit
        - 1 row = 1 student-term combination
        - 1 row = 1 student
    - Every column is either an *identifier* or a *measured variable*
        - rule of thumb: 1 row = 1 unique combination of identifiers
        - major table
            - identifiers: student ID, `term`
            - measured variables: admit term, relative term, major
            - NB the `term` identifier is constructed from two measured variables
        - demographics table
            - identifier: student ID
            - measured variables: gender, race and ethnicity variables, first gen status, low income status, admission type, whether they ever majored in philosophy, major the semester they took their first philosophy course
            - NB here "measured variable" includes both variables in the raw data as well as variables I constructed for analysis purposes (`poc`, `demographic`)

## Tools for tidying data ##

```{r tidy_setup}
library(tidyverse)
theme_set(theme_minimal())

data_folder = file.path('data')
data_zip = file.path(data_folder, 'tidy.zip')
## Get the data
if (!file.exists(data_zip)) {
    download.file('https://github.com/data-science-methods/book/raw/master/data/tidy.zip', 
                  data_zip)
}
unzip(data_zip, overwrite = FALSE, exdir = data_folder)
```

### 3.1: The Pew Dataset ###

- `pivot_longer()`
- `if_else()`
- `fct_inorder()`

```{r load_pew}
pew_df = read_csv(file.path(data_folder, 'pew.csv'))
head(pew_df)
```

```{r tidy_pew}
pew_clean = pew_df %>% 
    ## Drop the row number column
    select(-X1) %>% 
    ## Lengthen: 1 row per religion x income level
    pivot_longer(cols = `<$10k`:`Don't know/refused`, 
                 names_to = 'income', 
                 values_to = 'freq') %>% 
    ## Cleaning `income`: 
    ## - Make "Don't know/refused" into NA
    ## - Coerce to ordered factor
    mutate(income = if_else(str_detect(income, "Don't know"), 
                            NA_character_, 
                            income), 
           income = fct_inorder(income))
head(pew_clean)
```

```{r plot_pew}
ggplot(pew_clean, aes(religion, freq, fill = fct_rev(income))) +
    geom_col() +
    scale_fill_viridis_d(na.value = 'grey50') +
    coord_flip()
```


### 3.1: The Billboard Dataset ###

- A little helper function for parsing
- `str_remove()`
- Coercion
- Date arithmetic

```{r, load_billboard}
billboard_df = read_csv(file.path(data_folder, 'billboard.csv'))
head(billboard_df)
```

```{r tidy_billboard}
#' Helper function to parse weeks to integers in the Billboard dataset
#' @param wk_chr Vector of week characters, with the pattern `c('wk1', 'wk2')`
#' @return Vector of integers, eg, `c(1L, 2L)`
parse_week = function(wk_chr) {
    wk_int = wk_chr %>% 
        str_remove('wk') %>% 
        as.integer()
    return(wk_int)
}

billboard_clean = billboard_df %>% 
    ## Drop the row number column
    select(-X1) %>% 
    ## Pivot week down and remove NA rows
    pivot_longer(cols = starts_with('wk'), 
                 names_to = 'week', 
                 values_to = 'rank') %>% 
    filter(!is.na(rank)) %>% 
    ## Parse week and calculate date
    ## NB Base R can handle date arithmetic
    ## For month arithmetic see ?lubridate::`%m+%`
    mutate(week = parse_week(week), 
           date = date.entered + (week-1)*7) %>% 
    ## Clean columns
    select(year, artist, time, track, date, week, rank)
head(billboard_clean)
```

NB. Base R includes methods for doing date arithmetic, eg, 
```{r}
as.Date('2020-04-30') + 1
```
If you need month arithmetic, check out the `lubridate` package, and specifically `%m+%` and related operators. 

```{r}
count(billboard_clean, artist, track) %>% 
    arrange(desc(n)) %>% 
    head()
```

### 3.2: The TB Dataset ###

- `haven` package
- `separate()`
- `case_when()`

```{r load_tb}
tb_df = haven::read_sav(file.path(data_folder, 'tb.sav'))
head(tb_df)
```

```{r tidy_tb}
tb_clean = tb_df %>% 
    ## One row per observation = country x gender x age group
    pivot_longer(m014:fu, 
                 names_to = 'column', 
                 values_to = 'cases') %>% 
    ## Separate gender and age
    separate(column, into = c('gender', 'age'), 
             sep = 1) %>% 
    ## Wrangle age: 
    ## - Split into upper and lower bounds
    ## - Recombine with -
    ## - Fix missing age and 65+
    ## - Set order
    ## - Clean up the intermediate columns for upper and lower bounds
    separate(age, into = c('age_lower', 'age_upper'), 
             sep = -2) %>% 
    mutate(age = str_c(age_lower, '-', age_upper), 
           age = case_when(age == '-u'  ~ NA_character_, 
                           age == '-65' ~ '65+', 
                           TRUE         ~ age), 
           age = fct_inorder(age)) %>% 
    select(-age_lower, -age_upper) %>% 
    ## Put in order, with ID columns first and then the variable
    select(country, year, gender, age, cases)
head(tb_clean)
```

### 3.3: The Weather Dataset ###

- `pivot_wider()`
- `str_remove()`

```{r load_weather}
weather_df = read_csv(file.path(data_folder, 'weather.csv'))
head(weather_df)
```

```{r tidy_weather}
weather_clean = weather_df %>% 
    select(-X1) %>% 
    ## Lengthen days
    pivot_longer(d1:d31, 
                 names_to = 'day', 
                 values_to = 'obs') %>% 
    ## Widen `element`
    pivot_wider(names_from = element, 
                values_from = obs) %>% 
    ## Fix the class of `day`
    mutate(day = str_remove(day, 'd'), 
           day = as.integer(day)) %>% 
    ## Check against the paper by filtering to non-missing rows
    filter(!is.na(tmax) | !is.na(tmin))
head(weather_clean)
```
    
