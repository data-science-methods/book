{
  "hash": "12725a0778a71b5949c191f60df19695",
  "result": {
    "markdown": "# Visual EDA \n\n## Reading\n\n- Reading: @WeissgerberBarLineGraphs2015\n- Further reading: @HealyDataVisualizationPractical2018, ch. 1; @MatejkaSameStatsDifferent\n\n## The Role of Visuals in EDA ##\n\n- @TukeyExploratoryDataAnalysis1977 emphasized visual methods for EDA\n- Including not just graphs but also structured tables, such as [stem-and-leaf displays](https://en.wikipedia.org/wiki/Stem-and-leaf_display)\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A stem-and-leaf display, promoted by Tukey for use in EDA](images/03-eda/Stem_leaf_plot_001.png){width=30%}\n:::\n:::\n\n---\n\n## In terms of our models of EDA ##\n\n### Epicycle of analysis\n\n- Check expectations about the distribution of variables\n    - Outliers \n    - Degeneracies (eg, perfect correlation)\n    - Skew or bimodal distributions\n    - Non-linear relationships\n- Develop expectations about relationships between variables\n\n### Phenomena development \n\n- Quickly identify potential patterns\n- Contrast potential patterns with noise/uncertainty/imprecision\n\n\n## Plot Your Data ##\n\n- Summary statistics almost always focus only on central tendency (mean, median) and dispersion (standard deviation, IQR)\n    - This is all you would need if the world were made of normal distributions\n        - (Or at least unimodal symmetric ones)\n    - The world is not made of normal distributions [@LyonWhyAreNormal2014]\n        - (Or even unimodal symmetric ones) \n\n- We'll illustrate this using The Datasaurus Dozen [@MatejkaSameStatsDifferent]\n\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(datasauRus)\nlibrary(ggforce)\n\n## We'll need this, but don't want to load it\n## install.packages('Hmisc')\n\ntheme_set(theme_minimal())\n\nds_df = datasaurus_dozen\n```\n:::\n\n---\n\n- The dataset combines 13 different datasets with $n=142$ for each\n\n::: {.cell}\n\n```{.r .cell-code}\nds_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,846 × 3\n   dataset     x     y\n   <chr>   <dbl> <dbl>\n 1 dino     55.4  97.2\n 2 dino     51.5  96.0\n 3 dino     46.2  94.5\n 4 dino     42.8  91.4\n 5 dino     40.8  88.3\n 6 dino     38.7  84.9\n 7 dino     35.6  79.9\n 8 dino     33.1  77.6\n 9 dino     29.0  74.5\n10 dino     26.2  71.4\n# … with 1,836 more rows\n```\n:::\n\n```{.r .cell-code}\ncount(ds_df, dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 13 × 2\n   dataset        n\n   <chr>      <int>\n 1 away         142\n 2 bullseye     142\n 3 circle       142\n 4 dino         142\n 5 dots         142\n 6 h_lines      142\n 7 high_lines   142\n 8 slant_down   142\n 9 slant_up     142\n10 star         142\n11 v_lines      142\n12 wide_lines   142\n13 x_shape      142\n```\n:::\n:::\n\n---\n\n\n- The datasets have the same means, standard deviations, and (Pearson) correlation coefficient\n    - p-value of the correlation coefficient is not statistically significant\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## This is a more complex summarize() call than we've seen before\n## 1. Number of rows\n## 2. \"Summarize across the columns x and y, using the functions mean and sd\"; automatically generates names\n## 3. Correlation between x and y\n## 4. p-value from a t-test of the null that the correlation = 0\nds_df %>% \n    group_by(dataset) %>% \n    summarize(n = n(), \n              across(.cols = c(x, y), \n                     .fns = lst(mean, sd)), \n              cor_xy = cor(x, y), \n              p_value = cor.test(x, y)$p.value) %>% \n    ungroup()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 13 × 8\n   dataset        n x_mean  x_sd y_mean  y_sd  cor_xy p_value\n   <chr>      <int>  <dbl> <dbl>  <dbl> <dbl>   <dbl>   <dbl>\n 1 away         142   54.3  16.8   47.8  26.9 -0.0641   0.448\n 2 bullseye     142   54.3  16.8   47.8  26.9 -0.0686   0.417\n 3 circle       142   54.3  16.8   47.8  26.9 -0.0683   0.419\n 4 dino         142   54.3  16.8   47.8  26.9 -0.0645   0.446\n 5 dots         142   54.3  16.8   47.8  26.9 -0.0603   0.476\n 6 h_lines      142   54.3  16.8   47.8  26.9 -0.0617   0.466\n 7 high_lines   142   54.3  16.8   47.8  26.9 -0.0685   0.418\n 8 slant_down   142   54.3  16.8   47.8  26.9 -0.0690   0.415\n 9 slant_up     142   54.3  16.8   47.8  26.9 -0.0686   0.417\n10 star         142   54.3  16.8   47.8  26.9 -0.0630   0.457\n11 v_lines      142   54.3  16.8   47.8  26.9 -0.0694   0.412\n12 wide_lines   142   54.3  16.8   47.8  26.9 -0.0666   0.431\n13 x_shape      142   54.3  16.8   47.8  26.9 -0.0656   0.438\n```\n:::\n:::\n\n---\n\n- But, when plotted, they're obviously very different \n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ds_df, aes(x, y)) +\n    geom_point() +\n    facet_wrap(vars(dataset))\n```\n\n::: {.cell-output-display}\n![](03-05-graphs_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n## Bar plots, and better than bar plots ##\n\n- @WeissgerberBarLineGraphs2015 argue for the importance of plotting data, not just summaries, even in publications\n\n- Let's pull a few datasets out of datasaurus, as though they were groups in a study\n\n::: {.cell}\n\n```{.r .cell-code}\ncdw_df = ds_df |> \n    filter(dataset %in% c('circle', 'dino', 'wide_lines'))\n```\n:::\n\n## A bar plot of mean + 95% CI\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(cdw_df, aes(x = dataset, \n                   y = x)) +\n    stat_summary(geom = 'errorbar', width = 0.2,\n                 fun.data = mean_cl_boot, \n                 fun.args = list(conf.int = .95)) +\n    stat_summary(geom = 'bar', fun = mean, \n                 aes(fill = dataset)) +\n    scale_fill_viridis_d(guide = 'none')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Computation failed in `stat_summary()`:\n```\n:::\n\n::: {.cell-output-display}\n![](03-05-graphs_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n## Replace the bar with the data\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(cdw_df, aes(x = dataset, \n                   y = x)) +\n    # geom_point(aes(color = dataset)) +\n    geom_sina(aes(fill = dataset), \n              shape = 21L) +\n    stat_summary(geom = 'errorbar', width = 0.2,\n                 fun.data = mean_cl_boot) +\n    scale_color_viridis_d(guide = 'none', \n                          aesthetics = c('color', 'fill'))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Computation failed in `stat_summary()`:\n```\n:::\n\n::: {.cell-output-display}\n![](03-05-graphs_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n## Even fancier: Violin plot ##\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(cdw_df, aes(x = dataset, y = x, fill = dataset)) +\n    geom_violin(draw_quantiles = c(.5)) +\n    geom_sina(shape = 21, fill = 'white') +\n    scale_fill_viridis_d(guide = 'none')\n```\n\n::: {.cell-output-display}\n![](03-05-graphs_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n## References ##",
    "supporting": [
      "03-05-graphs_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}