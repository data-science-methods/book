{
  "hash": "79d8c1ef2cb4383d0520affd31e3edfb",
  "result": {
    "markdown": "# Exploratory Data Analysis {#eda-models}\n\n## <br>\n\n> This book is about exploratory data analysis, about looking at data to see what it seems to say. It concentrates on simple arithmetic and easy-to-draw pictures. It regards whatever appearances we have recognized as partial descriptions, and tries to look beneath them for new insights. Its concern is with appearance, not with confirmation. [@TukeyExploratoryDataAnalysis1977]\n\n> Exploratory Data Analysis (EDA) is \"an attitude, AND a flexibility, AND some graph paper (or transparencies, or both)\" [@TukeyWeNeedBoth1980]\n\n\n## Exploratory and Confirmatory Research ##\n\nEspecially in the wake of the replication crisis, one common distinction is between exploratory and confirmatory research [@WagenmakersAgendaPurelyConfirmatory2012]\n\n![@WagenmakersAgendaPurelyConfirmatory2012 figure 1. The caption reads, in part: \"A continuum of experimental exploration and the corresponding continuum of statistical wonkiness. On the far left of the continuum, researchers find their hypothesis in the data by post-hoc theorizing, and the corresponding statistics are 'wonky,' dramatically overestimating the evidence for the hypothesis.\"](https://journals.sagepub.com/cms/10.1177/1745691612463078/asset/images/large/10.1177_1745691612463078-fig1.jpeg)\n\n----\n\nTable: Exploratory vs. confirmatory research\n\n------------------------------------\nConfirmatory                    Exploratory\n---------------------           -------------------------------\nhypothesis testing              hypothesis development\n\nspecified in advance            adaptable\n\nalgorithmic                     free, creative\n\nmechanical objectivity\\          pure subjectivity? \n[@DastonObjectivity2007]\n\navoids inferential errors       *makes* errors?\n\n**rigorous**                    **lacking rigor?**\n\n**real science??**              **h\\*cking around with data??**\n\n**assumes experimental          **relevant to all methods**\nmethods**\n------------------------------------\n\n----\n\nI agree that it's important to\n\n- be thoughtful about how much confidence we're placing in our conclusions\n- interpret findings from one study in light of other studies\n\n\\\nBut the confirmatory/exploratory distinction can overhype the confirmatory side\n    \n- Making us too rigid and narrow-minded about what counts as good science\n\n\n## Better Models for EDA I: Developing Phenomena ##\n\n@BogenSavingPhenomena1988 by way of @BrownSmokeMirrorsHow2002\n\nTable: The data/phenomena/theory distinction\n\n-------------------------------------\n                                               Theories/\nData                    Phenomena              Causal processes\n---------------------   ---------------------  ---------------------\nEx: Spreadsheet of      Ex: Correlation        Ex:  Conservative\nnumbers, downloaded     between                susceptibility to \nfrom Qualtrics          partisanship and       anxiety hypothesis\n                        sharing Covid \n                        misinformation\n                        \n\\                                                                                       \n\ncollected               abstracted or          postulated\n                        extracted from data\n\nnot explained           explained by theories  explain phenomena\n\nhighly local to         varying scope          universal?\ntime, place, sample,\nprocedure\n\n\"raw,\" messy,           \"processed,\" clean,    \"laws of nature\"? \nunwieldy                stylized\n\n-------------------------------------\n\n## EDA as phenomena development ##\n\n- cleaning messy data \n    - identifying and mitigating (where possible) errors and idiosyncracies\n- identifying *local* patterns (\"local phenomena\")\n\n\\\n\n- **not yet claiming these will be stable and appear elsewhere**\n- **not yet worrying (much) about explanations**\n\n\n## Better Models for EDA II: Epicycle of Analysis ##\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Epicycle of analysis model, @PengArtDataScience2016, 5](images/03-eda/epicycle.png){width=30%}\n:::\n:::\n\n\n## @PengArtDataScience2016\n\n- Data analysis is organized into 5 activities\n- Each activity involves the same 3-step \"epicycle\" process\n    1. Develop expectations\n    2. Collect information\n    3. Compare and revise expectations\n\n- Not \"the scientific method\"! [@PengArtDataScience2016 4]\n    - \"Highly iterative and non-linear\"\n    - \"information is learned at each step, which then informs\n        - **whether (and how) to refine, and redo, the [previous] step** ..., or\n        - whether (and how) to proceed to the next step.\" \n\n## </br>\n\nTable: Aligning the goals of EDA with steps in the \"epicycle of analysis\" [@PengArtDataScience2016]\n\n----------------------------------------------------------------------- \nGoals of EDA                     Epicycle step\n------------------------         ------------------------\nDetermine if there are           2. Collecting information\nproblems with the data     \n     \nDetermine whether our            3. Comparing and revising expectations\nquestion can be answered     \nwith these data     \n     \nDevelop sketch of an             1. Developing expectations\nanswer\n------------------------------------------------------------------------\n\n## Discussion\n\n- For each of these models, how well do they fit the way you've been taught to do science? \n- How do they challenge the way you've been taught to do science? \n\n## References \n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}