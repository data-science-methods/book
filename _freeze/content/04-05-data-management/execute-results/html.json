{
  "hash": "e0f5aebb45adf4dabaf01f82fa155010",
  "result": {
    "markdown": "# Project and data management\n\n## Reading\n\n- @LaskowskiWhatWhenYou\n- @NobleQuickGuideOrganizing2009\n- @WilkinsonFAIRGuidingPrinciples2016\n- @JenningsApplyingCAREPrinciples2023\n\n## Some data management disasters\n\n- @ArrayErrors2011, @VideoKeithBaggerly\n- @HerndonDoesHighPublic2014, but you can just read @BaileyReinhartRogoffErrorHow, @CassidyReinhartRogoffControversy, and/or watch @ReinhartRogoffGrowth2019\n- @LaskowskiWhatWhenYou, @ViglioneAvalancheSpiderpaperRetractions2020, @PennisiProminentSpiderBiologist2020\n- @HowExcelMay2020\n\n## Dumpster organization\n\n![ðŸ˜± Source: <https://pbs.twimg.com/media/DFca5SRXsAAx1NA>](images/04-reproducibility/dumpster.jpg)\n\n- Dump all of your files into one place\n- Use search tools to find what you want\n- Just assume that things aren't getting corrupted\n- The way many Gen Z students think about their files?  [@ChinStudentsWhoGrew2021]\n\n## The first rule of data management</br> Do not edit your data\n\n\n## Project organization\n\n![Noble's [-@NobleQuickGuideOrganizing2009] sample folder structure is designed for experimental biologists](images/04-reproducibility/noble.png)\n\n- Keep your project self-contained\n- Locate files quickly\n- Play nicely with version control\n- *Self-document key relationships between project files*\n- *Work with your data without editing it*\n\n## A model for computational social science projects\n\n```\n.\nâ”œâ”€â”€ DESCRIPTION\nâ”œâ”€â”€ Makefile\nâ”œâ”€â”€ R\nâ”œâ”€â”€ data\nâ”œâ”€â”€ paper\nâ”‚Â Â  â”œâ”€â”€ Makefile\nâ”‚Â Â  â”œâ”€â”€ _quarto.yml\nâ”‚Â Â  â”œâ”€â”€ paper.qmd\nâ”œâ”€â”€ plots\nâ”œâ”€â”€ readme.md\nâ”œâ”€â”€ scripts\nâ”‚Â Â  â””â”€â”€ Makefile\nâ””â”€â”€ talk\n    â”œâ”€â”€ Makefile\n    â”œâ”€â”€ talk.pdf\n    â””â”€â”€ talk.tex\n```\n\n- <https://github.com/dhicks/project_template>\n\n- Configured as a GitHub \"template,\" making it easy to create new repositories for new projects\n\n- Designated folders for data, plots/outputs, and utility functions\n\n## File naming convention\n\nFiles in `scripts`, `data`, and `plots` should generally use a sequential naming convention:  \n\n- Scripts in `scripts` should have filenames starting with `01_`:\n\t- `01_scrape.R`\n\t- `02_parse.R`\n\t- `03_eda.R`, and so on\n\t\n- Data and plot files (`data` and `plots`) should use a parallel naming convention:  \n\t- `00_` indicates raw data (produced or gathered outside of the pipeline in `scripts`)\n\t- `01_` indicates plots and intermediate data files produced by script number `01`, and so on\n\n\n## The model in action: A mid-sized text-mining project\n\nPublished paper: <https://doi.org/10.1162/qss_a_00150>\\\nGitHub repo: <https://github.com/dhicks/orus>\\\n23 directories, 274 files (plus 160k data files)\n\n```\n.\nâ”œâ”€â”€ Makefile\nâ”œâ”€â”€ ORU\\ faculty\nâ”‚Â Â  â”œâ”€â”€ ORU\\ Faculty.docx\nâ”‚Â Â  â”œâ”€â”€ ORU\\ Faculty.html\nâ”‚Â Â  â”œâ”€â”€ ORU\\ Publications.docx\nâ”‚Â Â  â”œâ”€â”€ ORU\\ Publications.fld\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ colorschememapping.xml\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ filelist.xml\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ header.html\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ image001.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ item0001.xml\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ props002.xml\nâ”‚Â Â  â”‚Â Â  â””â”€â”€ themedata.thmx\nâ”‚Â Â  â”œâ”€â”€ ORU\\ Publications.html\nâ”‚Â Â  â””â”€â”€ auids.csv\nâ”œâ”€â”€ ORU\\ founding\\ dates.gsheet\nâ”œâ”€â”€ QSS\\ forms\nâ”‚Â Â  â”œâ”€â”€ QSS-Checklist-AcceptedManuscripts.docx\nâ”‚Â Â  â”œâ”€â”€ QSS_pub_agreement.pdf\nâ”‚Â Â  â””â”€â”€ Quantitative\\ Science\\ Studies\\ -\\ Decision\\ on\\ Manuscript\\ ID\\ QSS-2021-0014.R2.eml\nâ”œâ”€â”€ R\nâ”‚Â Â  â”œâ”€â”€ api_keys.R\nâ”‚Â Â  â””â”€â”€ hellinger.R\nâ”œâ”€â”€ auid\\ flow.txt\nâ”œâ”€â”€ data\nâ”‚Â Â  â”œâ”€â”€ *ORUs\\ -\\ DSL\\ -\\ Google\\ Drive.webloc\nâ”‚Â Â  â”œâ”€â”€ 00_UCD_2016.csv\nâ”‚Â Â  â”œâ”€â”€ 00_UCD_2017.csv\nâ”‚Â Â  â”œâ”€â”€ 00_UCD_2018.csv\nâ”‚Â Â  â”œâ”€â”€ 00_faculty_list.html\nâ”‚Â Â  â”œâ”€â”€ 00_manual_matches.csv\nâ”‚Â Â  â”œâ”€â”€ 00_publications_list.html\nâ”‚Â Â  â”œâ”€â”€ 01_departments.csv\nâ”‚Â Â  â”œâ”€â”€ 01_departments_canonical.csv\nâ”‚Â Â  â”œâ”€â”€ 01_faculty.Rds\nâ”‚Â Â  â”œâ”€â”€ 02_pubs.Rds\nâ”‚Â Â  â”œâ”€â”€ 03_codepartmentals.Rds\nâ”‚Â Â  â”œâ”€â”€ 03_dropout.Rds\nâ”‚Â Â  â”œâ”€â”€ 03_matched.Rds\nâ”‚Â Â  â”œâ”€â”€ 03_unmatched.Rds\nâ”‚Â Â  â”œâ”€â”€ 04_author_meta.Rds\nâ”‚Â Â  â”œâ”€â”€ 04_dropouts.Rds\nâ”‚Â Â  â”œâ”€â”€ 04_genderize\nâ”‚Â Â  â”œâ”€â”€ 04_namsor.Rds\nâ”‚Â Â  â”œâ”€â”€ 05_author_meta.Rds\nâ”‚Â Â  â”œâ”€â”€ 05_dept_dummies.Rds\nâ”‚Â Â  â”œâ”€â”€ 05_dropouts.Rds\nâ”‚Â Â  â”œâ”€â”€ 05_layout.Rds\nâ”‚Â Â  â”œâ”€â”€ 05_matched.Rds\nâ”‚Â Â  â”œâ”€â”€ 06_author_histories.Rds\nâ”‚Â Â  â”œâ”€â”€ 07_coauth_count.Rds\nâ”‚Â Â  â”œâ”€â”€ 07_parsed_histories.Rds\nâ”‚Â Â  â”œâ”€â”€ 08_phrases.Rds\nâ”‚Â Â  â”œâ”€â”€ 09_H.Rds\nâ”‚Â Â  â”œâ”€â”€ 09_atm.csv\nâ”‚Â Â  â”œâ”€â”€ 09_vocab.tex\nâ”‚Â Â  â”œâ”€â”€ 10_atm.csv\nâ”‚Â Â  â”œâ”€â”€ 10_atm_pc.Rds\nâ”‚Â Â  â”œâ”€â”€ 10_aytm.csv\nâ”‚Â Â  â”œâ”€â”€ 10_aytm_comp.csv\nâ”‚Â Â  â”œâ”€â”€ 10_aytm_did.csv\nâ”‚Â Â  â”œâ”€â”€ 10_model_stats.Rds\nâ”‚Â Â  â”œâ”€â”€ 10_models.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_au_dept_xwalk.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_departments.csv\nâ”‚Â Â  â”œâ”€â”€ 11_departments_canonical.csv\nâ”‚Â Â  â”œâ”€â”€ 11_dept_dummies.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_dept_gamma.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_dept_term_matrix.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_oru_gamma.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_oru_term_matrix.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_test_train.Rds\nâ”‚Â Â  â”œâ”€â”€ 12_layout.Rds\nâ”‚Â Â  â”œâ”€â”€ author_histories [7665 entries exceeds filelimit, not opening dir]\nâ”‚Â Â  â”œâ”€â”€ authors_meta [6020 entries exceeds filelimit, not opening dir]\nâ”‚Â Â  â”œâ”€â”€ docs [145144 entries exceeds filelimit, not opening dir]\nâ”‚Â Â  â”œâ”€â”€ ldatuning_results\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ tuningResult_comp.Rds\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ tuningResult_comp.docx\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ tuningResult_comp.pdf\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ tuningResult_did.Rds\nâ”‚Â Â  â”‚Â Â  â””â”€â”€ tuningResult_did.pdf\nâ”‚Â Â  â”œâ”€â”€ ldatuning_results-20190415T164055Z-001.zip\nâ”‚Â Â  â”œâ”€â”€ parsed_blocks [430 entries exceeds filelimit, not opening dir]\nâ”‚Â Â  â”œâ”€â”€ pubs [282 entries exceeds filelimit, not opening dir]\nâ”‚Â Â  â””â”€â”€ temp\nâ”œâ”€â”€ interdisciplinarity\\ project\\ notes.gdoc\nâ”œâ”€â”€ notes.txt\nâ”œâ”€â”€ paper\nâ”‚Â Â  â”œâ”€â”€ QSS_a_00150-Hicks_Proof1.pdf\nâ”‚Â Â  â”œâ”€â”€ apa-6th-edition.csl\nâ”‚Â Â  â”œâ”€â”€ cover\\ letter.txt\nâ”‚Â Â  â”œâ”€â”€ diff.pdf\nâ”‚Â Â  â”œâ”€â”€ header.yaml\nâ”‚Â Â  â”œâ”€â”€ img\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ ORU_DAG.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ cites_regression.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ coauths_regression.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ conceptual_model.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ dept_dist_fixed_reg.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ dept_dist_reg.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ dept_gamma.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ dept_hell_net.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ dept_hell_net_50.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ entropies.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ entropies_selected.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ entropy_regression.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ gender.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ mds.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ mds_dept.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ network.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ oru_dept_entropy.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ oru_dept_min_dist.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ oru_dept_min_dist_ridges.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ oru_dept_network.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ oru_dept_org_dist.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ oru_dept_org_dist_ridges.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ oru_gamma.png\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ pub_regression.png\nâ”‚Â Â  â”‚Â Â  â””â”€â”€ sample.png\nâ”‚Â Â  â”œâ”€â”€ lit\\ review\\ notes.txt\nâ”‚Â Â  â”œâ”€â”€ oru_paper.aux\nâ”‚Â Â  â”œâ”€â”€ oru_paper.log\nâ”‚Â Â  â”œâ”€â”€ oru_paper.md\nâ”‚Â Â  â”œâ”€â”€ oru_paper.out\nâ”‚Â Â  â”œâ”€â”€ oru_paper.pdf\nâ”‚Â Â  â”œâ”€â”€ oru_paper.synctex.gz\nâ”‚Â Â  â”œâ”€â”€ oru_paper.tex\nâ”‚Â Â  â”œâ”€â”€ oru_paper.zip\nâ”‚Â Â  â”œâ”€â”€ oru_paper_20200616.pdf\nâ”‚Â Â  â”œâ”€â”€ oru_paper_20210805.pdf\nâ”‚Â Â  â”œâ”€â”€ oru_project.bib\nâ”‚Â Â  â”œâ”€â”€ oru_project.yaml\nâ”‚Â Â  â”œâ”€â”€ response1.gdoc\nâ”‚Â Â  â”œâ”€â”€ response1.pdf\nâ”‚Â Â  â”œâ”€â”€ response2.gdoc\nâ”‚Â Â  â”œâ”€â”€ response2.pdf\nâ”‚Â Â  â”œâ”€â”€ scraps\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ Hellinger.md\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ Holbrook.md\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ table.md\nâ”‚Â Â  â”‚Â Â  â””â”€â”€ table.pdf\nâ”‚Â Â  â”œâ”€â”€ supplement.md\nâ”‚Â Â  â””â”€â”€ supplement.pdf\nâ”œâ”€â”€ plots\nâ”‚Â Â  â”œâ”€â”€ 12_beta.tex\nâ”‚Â Â  â”œâ”€â”€ 12_cites_regression.png\nâ”‚Â Â  â”œâ”€â”€ 12_coauths_regression.png\nâ”‚Â Â  â”œâ”€â”€ 12_dept_dist_fixed_reg.png\nâ”‚Â Â  â”œâ”€â”€ 12_dept_dist_reg.png\nâ”‚Â Â  â”œâ”€â”€ 12_dept_gamma.png\nâ”‚Â Â  â”œâ”€â”€ 12_dept_hell_net.png\nâ”‚Â Â  â”œâ”€â”€ 12_dept_hell_net_50.png\nâ”‚Â Â  â”œâ”€â”€ 12_dept_topics.png\nâ”‚Â Â  â”œâ”€â”€ 12_entropies.png\nâ”‚Â Â  â”œâ”€â”€ 12_entropies_selected.png\nâ”‚Â Â  â”œâ”€â”€ 12_entropy_regression.png\nâ”‚Â Â  â”œâ”€â”€ 12_gender.png\nâ”‚Â Â  â”œâ”€â”€ 12_mds.png\nâ”‚Â Â  â”œâ”€â”€ 12_mds_dept.png\nâ”‚Â Â  â”œâ”€â”€ 12_mds_wide.png\nâ”‚Â Â  â”œâ”€â”€ 12_network.png\nâ”‚Â Â  â”œâ”€â”€ 12_oru_dept_entropy.png\nâ”‚Â Â  â”œâ”€â”€ 12_oru_dept_mean_dist.png\nâ”‚Â Â  â”œâ”€â”€ 12_oru_dept_mean_dist_ridges.png\nâ”‚Â Â  â”œâ”€â”€ 12_oru_dept_min_dist.png\nâ”‚Â Â  â”œâ”€â”€ 12_oru_dept_min_dist_ridges.png\nâ”‚Â Â  â”œâ”€â”€ 12_oru_dept_network.png\nâ”‚Â Â  â”œâ”€â”€ 12_oru_dept_org_dist.png\nâ”‚Â Â  â”œâ”€â”€ 12_oru_dept_org_dist_ridges.png\nâ”‚Â Â  â”œâ”€â”€ 12_oru_entropy.png\nâ”‚Â Â  â”œâ”€â”€ 12_oru_gamma.png\nâ”‚Â Â  â”œâ”€â”€ 12_pub_regression.png\nâ”‚Â Â  â”œâ”€â”€ 12_sample.png\nâ”‚Â Â  â””â”€â”€ ORU_DAG.png\nâ”œâ”€â”€ presentations\nâ”‚Â Â  â””â”€â”€ 2019-06-07\\ for\\ Paul\\ Dodd.gslides\nâ”œâ”€â”€ questions\\ for\\ jane.md\nâ”œâ”€â”€ scripts\nâ”‚Â Â  â”œâ”€â”€ 01_parse_faculty_list.R\nâ”‚Â Â  â”œâ”€â”€ 02_Scopus_search_results.R\nâ”‚Â Â  â”œâ”€â”€ 03_match.R\nâ”‚Â Â  â”œâ”€â”€ 03_matched.csv\nâ”‚Â Â  â”œâ”€â”€ 04_author_meta.R\nâ”‚Â Â  â”œâ”€â”€ 05_filtering.R\nâ”‚Â Â  â”œâ”€â”€ 06_author_histories.R\nâ”‚Â Â  â”œâ”€â”€ 07_complete_histories.R\nâ”‚Â Â  â”œâ”€â”€ 08_text_annotation.R\nâ”‚Â Â  â”œâ”€â”€ 09_build_vocab.R\nâ”‚Â Â  â”œâ”€â”€ 10_topic_modeling.R\nâ”‚Â Â  â”œâ”€â”€ 11_depts.R\nâ”‚Â Â  â”œâ”€â”€ 11_depts.html\nâ”‚Â Â  â”œâ”€â”€ 12_analysis\\ copy.html\nâ”‚Â Â  â”œâ”€â”€ 12_analysis-matched.html\nâ”‚Â Â  â”œâ”€â”€ 12_analysis.R\nâ”‚Â Â  â”œâ”€â”€ 12_analysis.html\nâ”‚Â Â  â”œâ”€â”€ 12_analysis_cache\nâ”‚Â Â  â”‚Â Â  â””â”€â”€ html\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ __packages\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz_efd9009c794d667852b2549df2bccf96.RData\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz_efd9009c794d667852b2549df2bccf96.rdb\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz_efd9009c794d667852b2549df2bccf96.rdx\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ network_c410cd78a4c339cdc4acd1d66c6c5e07.RData\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ network_c410cd78a4c339cdc4acd1d66c6c5e07.rdb\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ network_c410cd78a4c339cdc4acd1d66c6c5e07.rdx\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ silhouette_3170ef648aba325d2ce8c9be48c52e53.RData\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ silhouette_3170ef648aba325d2ce8c9be48c52e53.rdb\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ silhouette_3170ef648aba325d2ce8c9be48c52e53.rdx\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_viz_41d0cb157a88d4ec41810a16e769f5d5.RData\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_viz_41d0cb157a88d4ec41810a16e769f5d5.rdb\nâ”‚Â Â  â”‚Â Â      â””â”€â”€ topic_viz_41d0cb157a88d4ec41810a16e769f5d5.rdx\nâ”‚Â Â  â”œâ”€â”€ 12_analysis_files\nâ”‚Â Â  â”‚Â Â  â””â”€â”€ figure-html\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ author-dept\\ distance-1.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ author-dept\\ distance-2.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ author-dept\\ distance-3.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ author-dept\\ distance-4.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ author-dept\\ distance-5.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ desc_plots_tabs-1.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ desc_plots_tabs-2.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ desc_plots_tabs-3.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ desc_plots_tabs-4.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ h3-1.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ h3-2.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ h3-3.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ h3-4.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ h3-5.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ h3-6.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-1.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-10.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-11.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-12.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-13.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-14.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-2.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-3.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-4.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-5.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-6.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-7.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-8.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ mds_viz-9.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ network-1.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ network-2.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ productivity-1.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ productivity-2.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ productivity-3.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ productivity-4.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ productivity-5.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ productivity-6.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ productivity-7.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ productivity-8.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ productivity-9.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ silhouette-1.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-1.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-10.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-11.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-12.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-13.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-2.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-3.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-4.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-5.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-6.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-7.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-8.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_models-9.png\nâ”‚Â Â  â”‚Â Â      â”œâ”€â”€ topic_viz-1.png\nâ”‚Â Â  â”‚Â Â      â””â”€â”€ topic_viz-2.png\nâ”‚Â Â  â”œâ”€â”€ api_key.R\nâ”‚Â Â  â””â”€â”€ scraps\nâ”‚Â Â      â”œâ”€â”€ 02_parse_pubs_list.R\nâ”‚Â Â      â”œâ”€â”€ 03_coe_pubs.R\nâ”‚Â Â      â”œâ”€â”€ 03_match_auids.R\nâ”‚Â Â      â”œâ”€â”€ 07.R\nâ”‚Â Â      â”œâ”€â”€ 12_regressions.R\nâ”‚Â Â      â”œâ”€â”€ BML-CMSI\\ deep\\ dive.R\nâ”‚Â Â      â”œâ”€â”€ Hellinger_low_memory.R\nâ”‚Â Â      â”œâ”€â”€ dept_hell_net.R\nâ”‚Â Â      â”œâ”€â”€ divergence\\ against\\ lagged\\ distributions.R\nâ”‚Â Â      â”œâ”€â”€ exploring\\ topics.R\nâ”‚Â Â      â”œâ”€â”€ fractional_authorship.R\nâ”‚Â Â      â”œâ”€â”€ hellinger.R\nâ”‚Â Â      â”œâ”€â”€ model_scratch.R\nâ”‚Â Â      â”œâ”€â”€ multicore.R\nâ”‚Â Â      â”œâ”€â”€ net_viz.R\nâ”‚Â Â      â”œâ”€â”€ prcomp.R\nâ”‚Â Â      â”œâ”€â”€ propensity.R\nâ”‚Â Â      â”œâ”€â”€ rs_diversity.R\nâ”‚Â Â      â”œâ”€â”€ spacyr.R\nâ”‚Â Â      â”œâ”€â”€ topic\\ counts\\ rather\\ than\\ entropies.R\nâ”‚Â Â      â”œâ”€â”€ topic_cosine_sim.R\nâ”‚Â Â      â”œâ”€â”€ unit-level.R\nâ”‚Â Â      â”œâ”€â”€ weighted\\ regression.R\nâ”‚Â Â      â”œâ”€â”€ word-topic_distance.R\nâ”‚Â Â      â”œâ”€â”€ xx_construct_samples.R\nâ”‚Â Â      â””â”€â”€ xx_oru_complete_histories.R\nâ””â”€â”€ tree.md\n```\n\n## Just the directories\n\n```\n.\nâ”œâ”€â”€ ORU\\ faculty\nâ”‚Â Â  â””â”€â”€ ORU\\ Publications.fld\nâ”œâ”€â”€ QSS\\ forms\nâ”œâ”€â”€ R\nâ”œâ”€â”€ data\nâ”‚Â Â  â”œâ”€â”€ author_histories\nâ”‚Â Â  â”œâ”€â”€ authors_meta\nâ”‚Â Â  â”œâ”€â”€ docs\nâ”‚Â Â  â”œâ”€â”€ ldatuning_results\nâ”‚Â Â  â”œâ”€â”€ parsed_blocks\nâ”‚Â Â  â”œâ”€â”€ pubs\nâ”‚Â Â  â””â”€â”€ temp\nâ”œâ”€â”€ paper\nâ”‚Â Â  â”œâ”€â”€ img\nâ”‚Â Â  â””â”€â”€ scraps\nâ”œâ”€â”€ plots\nâ”œâ”€â”€ presentations\nâ””â”€â”€ scripts\n    â”œâ”€â”€ 12_analysis_cache\n    â”‚Â Â  â””â”€â”€ html\n    â”œâ”€â”€ 12_analysis_files\n    â”‚Â Â  â””â”€â”€ figure-html\n    â””â”€â”€ scraps\n```\n\n## Intermediate data files\n\n```\nâ”œâ”€â”€ data\nâ”‚Â Â  â”œâ”€â”€ *ORUs\\ -\\ DSL\\ -\\ Google\\ Drive.webloc\nâ”‚Â Â  â”œâ”€â”€ 00_UCD_2016.csv\nâ”‚Â Â  â”œâ”€â”€ 00_UCD_2017.csv\nâ”‚Â Â  â”œâ”€â”€ 00_UCD_2018.csv\nâ”‚Â Â  â”œâ”€â”€ 00_faculty_list.html\nâ”‚Â Â  â”œâ”€â”€ 00_manual_matches.csv\nâ”‚Â Â  â”œâ”€â”€ 00_publications_list.html\nâ”‚Â Â  â”œâ”€â”€ 01_departments.csv\nâ”‚Â Â  â”œâ”€â”€ 01_departments_canonical.csv\nâ”‚Â Â  â”œâ”€â”€ 01_faculty.Rds\nâ”‚Â Â  â”œâ”€â”€ 02_pubs.Rds\nâ”‚Â Â  â”œâ”€â”€ 03_codepartmentals.Rds\nâ”‚Â Â  â”œâ”€â”€ 03_dropout.Rds\nâ”‚Â Â  â”œâ”€â”€ 03_matched.Rds\nâ”‚Â Â  â”œâ”€â”€ 03_unmatched.Rds\nâ”‚Â Â  â”œâ”€â”€ 04_author_meta.Rds\nâ”‚Â Â  â”œâ”€â”€ 04_dropouts.Rds\nâ”‚Â Â  â”œâ”€â”€ 04_genderize\nâ”‚Â Â  â”œâ”€â”€ 04_namsor.Rds\nâ”‚Â Â  â”œâ”€â”€ 05_author_meta.Rds\nâ”‚Â Â  â”œâ”€â”€ 05_dept_dummies.Rds\nâ”‚Â Â  â”œâ”€â”€ 05_dropouts.Rds\nâ”‚Â Â  â”œâ”€â”€ 05_layout.Rds\nâ”‚Â Â  â”œâ”€â”€ 05_matched.Rds\nâ”‚Â Â  â”œâ”€â”€ 06_author_histories.Rds\nâ”‚Â Â  â”œâ”€â”€ 07_coauth_count.Rds\nâ”‚Â Â  â”œâ”€â”€ 07_parsed_histories.Rds\nâ”‚Â Â  â”œâ”€â”€ 08_phrases.Rds\nâ”‚Â Â  â”œâ”€â”€ 09_H.Rds\nâ”‚Â Â  â”œâ”€â”€ 09_atm.csv\nâ”‚Â Â  â”œâ”€â”€ 09_vocab.tex\nâ”‚Â Â  â”œâ”€â”€ 10_atm.csv\nâ”‚Â Â  â”œâ”€â”€ 10_atm_pc.Rds\nâ”‚Â Â  â”œâ”€â”€ 10_aytm.csv\nâ”‚Â Â  â”œâ”€â”€ 10_aytm_comp.csv\nâ”‚Â Â  â”œâ”€â”€ 10_aytm_did.csv\nâ”‚Â Â  â”œâ”€â”€ 10_model_stats.Rds\nâ”‚Â Â  â”œâ”€â”€ 10_models.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_au_dept_xwalk.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_departments.csv\nâ”‚Â Â  â”œâ”€â”€ 11_departments_canonical.csv\nâ”‚Â Â  â”œâ”€â”€ 11_dept_dummies.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_dept_gamma.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_dept_term_matrix.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_oru_gamma.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_oru_term_matrix.Rds\nâ”‚Â Â  â”œâ”€â”€ 11_test_train.Rds\nâ”‚Â Â  â”œâ”€â”€ 12_layout.Rds\n```\n\n## A reminder on paths\n\n- Windows and Unix-based systems write paths differently\n- Use `file.path()` or (even better) the `here` package to construct paths\n\n## Exercise: Organize your EDA\n\n\n```\n.\nâ”œâ”€â”€ R\nâ”œâ”€â”€ data\nâ”œâ”€â”€ paper\nâ”œâ”€â”€ plots\nâ”œâ”€â”€ readme.md\nâ”œâ”€â”€ scripts\nâ””â”€â”€ talk\n```\n\n\n\n\n\n\n\n## Documentation ##\n\n- Many social science fields have a tradition of writing codebooks for their data\n    - [Stanford Open Policing codebook](https://github.com/stanford-policylab/opp/blob/master/data_readme.md)\n    - [\"Codebook-like summary\" of the `covdata` package, automatically generated using `skimr`](https://kjhealy.github.io/covdata/articles/codebook.html)\n    - Caitlin Hudon's approach [@HudonFieldNotesBuilding2018]\n        - Table and field name, both verbatim\n        - Field example value\n        - Notes for both table and field\n\n(ref:Hudson-tbl) Example of Caitlin Hudon's approach to building a data dictionary. Source: <https://caitlinhudon.com/2018/10/30/data-dictionaries/>\n        \n\n::: {.cell}\n::: {.cell-output-display}\n![(ref:Hudson-tbl)](images/04-reproducibility/Hudon.png){width=80%}\n:::\n:::\n\n\n## Questions a codebook should answer\n\n1. What does this field mean? How should I use it? \n2. What is the data [journey]? \n    - Where does this data come from? \n    - How exactly is it collected? \n    - How often is it updated? \n    - Where does it go next? \n3. What does the data in this field actually look like? \n4. Are there any caveats to keep in mind when using this data? \n5. Where can I go for more information? \n\n[@HudonFieldNotesBuilding2018]\n\n \n## Major codebook elements \n\n(<https://afit-r.github.io/codebook>)\n\n1. Original source of the data\n2. Sampling information\n    - Where and how the data were generated\n3. Variable-level metadata and summaries\n4. Structure of the data\n\n\n## Data management plans ##\n\n- Much like a research plan, data management plans provide an overview of the steps you'll take to gather, publish, and maintain your data\n    - Since 2011, NSF has required a 2-page data management plan for most types of proposals\n\n- Examples and resources\n    - [UCM Library](https://library.ucmerced.edu/research/researchers/research-data-management/data-management-plans)\n    <!-- - [UCM IT support](https://it.ucmerced.edu/content/research-data-management-consultation-service) -->\n    - [UCSD NSF examples](https://library.ucsd.edu/lpw-staging/research-and-collections/data-curation/data-management/dmp-samples.html)\n        - [SBE example 1](https://library.ucsd.edu/lpw-staging/research-and-collections/data-curation/data-management/dmpsample/DMP-Example-Ayelet-Gneezy.pdf)\n        - [SBE example 2](https://library.ucsd.edu/lpw-staging/research-and-collections/data-curation/data-management/dmpsample/DMP-Example-Wixted.pdf)\n    - [NSF policy summary](https://www.nsf.gov/bfa/dias/policy/dmp.jsp)\n        - [SBE-specific guidance](https://www.nsf.gov/sbe/DMP/SBE_DataMgmtPlanPolicy_RevisedApril2018.pdf)\n    \n## Data management plan: Common elements \n\n- Who is responsible for data management\n- Who else will have access to which data\n- How data will be collected\n- Data formatting standards\n- Whether and how data will be archived and made available for reuse\n\n\n## FAIR principles for published data ##\n\n- *Findable*\n    - F1. (meta)data are assigned a globally unique and persistent identifier\n    - F2. data are described with rich metadata (defined by R1 below)\n    - F3. metadata clearly and explicitly include the identifier of the data it describes \n    - F4. (meta)data are registered or indexed in a searchable resource\n- *Accessible*\n    - A1. (meta)data are retrievable by their identifier using a standardized communications protocol \n        - A1.1 the protocol is open, free, and universally implementable\n        - A1.2 the protocol allows for an authentication and authorization procedure, where necessary \n    - A2. metadata are accessible, even when the data are no longer available\n- *Interoperable*\n    - I1. (meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation. \n    - I2. (meta)data use vocabularies that follow FAIR principles\n    - I3. (meta)data include qualified references to other (meta)data\n- *Reusable*\n    - R1. meta(data) are richly described with a plurality of accurate and relevant attributes \n        - R1.1. (meta)data are released with a clear and accessible data usage license\n        - R1.2. (meta)data are associated with detailed provenance\n        - R1.3. (meta)data meet domain-relevant community standards\n\n\n## DOIs for data\n\n- [Instructions for OSF](https://help.osf.io/hc/en-us/articles/360019931013-Create-DOIs)\n- [Notes for Zenodo](https://help.zenodo.org/#versioning)\n    - [Zenodo also plays nicely with GitHub for minting DOIs for code](https://guides.github.com/activities/citable-code/)\n- [Citation models at Harvard Dataverse](https://dataverse.org/best-practices/data-citation)\n\n<!--\n## Hazards of open data ##\n\n- Legal\n    - Privacy\n        - Personally identifiable information (PII): \"information which can be used to **distinguish or trace an individual's identity**, such as their name, social security number, biometric records, etc. *alone, or when combined with other ... information*\" [Source](https://www.osec.doc.gov/opog/privacy/PII_BII.html)\n        - Sensitive information: \"if the loss, compromission [sic], or disclosure without authorization of this data could **result in harm, embarrassment, inconvenience, or unfairness** to an individual\" [Source](https://techgdpr.com/blog/difference-between-pii-and-personal-data/)\n        - IRB will require you to\n            - indicate what PII and sensitive information you're collecting\n            - explain why you need to collect it\n            - outline a plan to keep it secure\n            - notify or mitigate issues with participants if security is compromised\n\n    - Copyright\n        - Data that you've bought from a broker\n        - Journal article text, *but also* article metadata if you used a private service to retrieve it\n    \n- Community-level hazards\n    - Location of endangered species [@OpenDataOffer2018]\n    - Indigenous community sacred sites\n    - Antiquities\n    - Identifying the Golden State Killer through GEDmatch [@ZhangHowTinyWebsite2018]\n \n- Public-but-inaccessible data\n    - OKCupid data scrape [@McCookPubliclyAvailableData2016]\n        - [Emil O. Kierkegaard is a racist asshole; don't be like Emil O. Kierkegaard](https://rationalwiki.org/wiki/Emil_Kirkegaard)\n-->\n\n## References \n\n\n    ",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}